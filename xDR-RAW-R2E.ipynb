{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARSIS xDR-RAW Read To Export (R2E)\n",
    "@author: Giacomo Nodjoumi g.nodjoumi@jacobs-unversity.de\n",
    "\n",
    "## Create and activate the environment using the yml\n",
    "\n",
    "Using the terminal, craate conda env using provided MARSISv2.yml:\n",
    "* `conda env create -f MARSISv2.yml`\n",
    "* `conda activate MARSISv2`\n",
    "\n",
    "## Arguments requested to user:\n",
    "* Output Directory: path where all files are saved\n",
    "* Data directory: path where are all files to be processed\n",
    "* Driver for gis output: insert choice between GPKG, gpkg, SHP, shp\n",
    "* Data record type: insert choice between EDR, edr, RDR, rdr, RAW, raw\n",
    "* Flag for save images of both frequencies: insert choice between Y,y,N,n\n",
    "* Flag for save numpy dump of both frequencies: insert choice between Y,y,N,n\n",
    "* Flag for save seg-y of both frequencies: insert choice between Y,y,N,n\n",
    "* Flag for ingest data into database Y,y,N,n\n",
    "* Flag for select destination CRS\n",
    "\n",
    "## Outputs:\n",
    "### GIS OUTPUTS\n",
    "It creates three different geopackages:\n",
    "    - FULL with all orbits\n",
    "    - North Pole with orbits from 65째->90째 Latitude\n",
    "    - South Pole with orbits from -65째->-90째 Latitude\n",
    "    \n",
    "### Image outputs\n",
    "As default it creates thre types of images for each frequency:\n",
    "* Original image\n",
    "* Normalized image\n",
    "* Scaled image using sklearn MinMaxScaler\n",
    "\n",
    "*Further image processing is in development*\n",
    "### SEG-Y outputs\n",
    "It export a seg-y file for each frequency of each image\n",
    "\n",
    "### Ingestion into postgres+postgis database\n",
    "Connection to database and ingestion parameters must be set into utils/DB_utils.py\n",
    "**Provided configuration is just an example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package and sub-modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from statistics import mean\n",
    "from shapely.geometry import LineString\n",
    "from pyproj.crs import CRS\n",
    "from pyproj import Transformer\n",
    "from ipywidgets import IntProgress\n",
    "import re\n",
    "import itertools\n",
    "from utils.FileUtils import DAT2FILE\n",
    "from utils.GenUtils import get_paths, make_folder, question,folder_file_size\n",
    "from utils.ReprojUtils import coordTransformer\n",
    "from utils.DFUtils import DF_drop, geoDF2file, gdf_split, xDR_DF\n",
    "from utils.RawUtils import raw_reader\n",
    "from utils.SegyUtils import assemply_segy, save_segy\n",
    "from utils.DBUtils import databaseUpdate\n",
    "from utils.DFUtils import xDR_params\n",
    "from utils.DFUtils import RAW_params\n",
    "from utils.DFUtils import FM_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define CRS for global, North and South poles of MARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Available_CRS = {'N_pole':CRS.from_proj4('+proj=stere +lat_0=90 +lon_0=0 +k=1 +x_0=0 +y_0=0 +a=3396190 +b=3376200 +units=m +no_defs '),\n",
    "                 'S_pole':CRS.from_proj4('+proj=stere +lat_0=-90 +lon_0=0 +k=1 +x_0=0 +y_0=0 +a=3396190 +b=3376200 +units=m +no_defs '),\n",
    "                 'Planetocentric':CRS.from_proj4('+proj=longlat +a=3396190 +b=3376200 +no_defs'),\n",
    "                 'EquidistantCylindrical-180':CRS.from_user_input('PROJCS[\"Mars_Equidistant_Cylindrical\",GEOGCS[\"Mars 2000\",DATUM[\"D_Mars_2000\",SPHEROID[\"Mars_2000_IAU_IAG\",3396190.0,169.89444722361179]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.017453292519943295]],PROJECTION[\"Equidistant_Cylindrical\"],PARAMETER[\"False_Easting\",0],PARAMETER[\"False_Northing\",0],PARAMETER[\"Central_Meridian\",180],PARAMETER[\"Standard_Parallel_1\",0],UNIT[\"Meter\",1]]')\n",
    "                 \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core function\n",
    "This is the core function that read the binary data file and convert it into:\n",
    "- a complete dataframe\n",
    "- a complete geodataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RAW2GeoDF(xDR_df, xDR_gdf, xDrFile, ParamDF, def_crs):\n",
    "    fname = pathlib.Path(xDrFile).name.split('.')[0]\n",
    "    #F_NAME = re.split('_|\\.', fname)[0:6]\n",
    "    full_parameters = [] #All values for each parameter\n",
    "    short_parameters = [] #Mean value for each parameter\n",
    "    \n",
    "\n",
    "    for i in range(len(ParamDF['NAME'])):\n",
    "        #print(ParamDF['NAME'][i])\n",
    "        offBytes=ParamDF['START_BYTES'][i]\n",
    "        precision = ParamDF['DATA_TYPE'][i]\n",
    "        Items = ParamDF['ITEMS'][i]\n",
    "        ItemBytes=ParamDF['ITEM_BYTES'][i]\n",
    "        file = open(xDrFile, 'rb')\n",
    "        FileSize = pathlib.Path(xDrFile).stat().st_size\n",
    "        RecordBytes=ParamDF['RECORD_BYTES'][0]\n",
    "        FileRecord = int(FileSize/RecordBytes)\n",
    "        f = file.read()\n",
    "        if Items > 1 and 'S' not in precision:\n",
    "            values=[]\n",
    "            mean_values = []\n",
    "            for l in range(Items):\n",
    "                Item = l*ItemBytes\n",
    "                val = np.array(raw_reader(f,offBytes,i,FileRecord,Item,RecordBytes, precision))\n",
    "                values.append(val)\n",
    "                mean_values.append(mean(val))\n",
    "        else:\n",
    "            Item=0\n",
    "            values = np.array(raw_reader(f,offBytes,i,FileRecord,Item,RecordBytes, precision))\n",
    "            if 'S' in precision:\n",
    "                mean_values= values[0]\n",
    "            else:\n",
    "                mean_values=mean(values)\n",
    "        full_parameters.append(values)\n",
    "        short_parameters.append(mean_values)\n",
    "        file_name=fname.split('.')[0]\n",
    "\n",
    "\n",
    "    if DRTYPE in ['RDR', 'rdr','EDR','edr']:\n",
    "        a, b,c,d = [11,17,29,30]\n",
    "        F= [full_parameters[a], full_parameters[b]]\n",
    "        coord = list(zip(full_parameters[c], full_parameters[d]))\n",
    "        # lat_mean = mean(full_parameters[d])\n",
    "        \n",
    "    elif DRTYPE in ['RAW','raw']:\n",
    "        a, b,c,d = [9,11,21,22]\n",
    "        F= [full_parameters[a], full_parameters[b]]\n",
    "        coord = list(zip(full_parameters[c], full_parameters[d]))\n",
    "        # lat_mean = mean(full_parameters[d])\n",
    "        \n",
    "\n",
    "    if SAVESEGY in ['Y','y']:\n",
    "        if DRTYPE in ['RDR', 'rdr','EDR','edr']:\n",
    "            dt_value = (7.14285714285714e-03)/2\n",
    "            scl = -10\n",
    "            segy_crs = Available_CRS['EquidistantCylindrical-180']\n",
    "                \n",
    "        elif DRTYPE in ['RAW','raw']:\n",
    "            scl = -1\n",
    "            dt_value = (7.14285714285714e-03)/2\n",
    "            segy_crs = Available_CRS['EquidistantCylindrical-180']\n",
    "                \n",
    "        segy_coord = coordTransformer(coord, def_crs, segy_crs)            \n",
    "        DAT2FILE(IMG_DIR, DUMP_DIR, SEGY_DIR, file_name, F, SAVEDUMP,\n",
    "                 SAVEIMG, SAVESEGY, segy_coord, dt=dt_value ,pp='y',scaler=scl)\n",
    "            \n",
    "            \n",
    "    if DBUP in ['Y','y']:\n",
    "        if DRTYPE in ['RDR','rdr']:\n",
    "            indxs = [32,33,35,36]\n",
    "        else:\n",
    "            indxs = [24,25,27,28]\n",
    "        \n",
    "        new_params = {'c1min':min(full_parameters[indxs[0]-3]),\n",
    "                      'c1max':max(full_parameters[indxs[0]-3]),\n",
    "                      'c2min':min(full_parameters[indxs[1]-3]),\n",
    "                      'c2max':max(full_parameters[indxs[1]-3])\n",
    "                      }\n",
    "        \n",
    "        short_cols = xDR_df.columns.tolist()\n",
    "        \n",
    "        for ii in range(len(new_params.keys())):\n",
    "            print(ii)\n",
    "            key = list(new_params.keys())[ii]\n",
    "            print(key)\n",
    "            val = new_params[key]\n",
    "            print(val)\n",
    "            short_cols.insert(indxs[ii], key)\n",
    "            short_parameters.insert(indxs[ii]-2,val)\n",
    "   \n",
    "    \n",
    "    # Create entries for dataframe\n",
    "    dst_crs = DST_CRS\n",
    "    proj4= dst_crs.to_proj4()#.to_wkt()\n",
    "    meta = [fname, proj4]\n",
    "    \n",
    "    \n",
    "    \n",
    "    temp_full = meta+full_parameters\n",
    "    series_full = pd.Series(temp_full, index=xDR_df.columns)\n",
    "    xDR_df = xDR_df.append(series_full,ignore_index=True)\n",
    "   \n",
    "    if def_crs != dst_crs:\n",
    "        dst_coord = coordTransformer(coord, def_crs, dst_crs)\n",
    "    else:\n",
    "        dst_coord = coord\n",
    "    \n",
    "    \n",
    "    track = LineString(dst_coord)\n",
    "    trans_coord = None\n",
    "    # create the geoSeries\n",
    "    gser = gpd.GeoSeries(track)\n",
    "    \n",
    "    # Create a temporary dataframe containing all mean values for each parameter\n",
    "    temp_short = meta+short_parameters\n",
    "    series_short = pd.Series(temp_short, index=short_cols)\n",
    "    df = pd.DataFrame(columns=short_cols).append(series_short, ignore_index=True)\n",
    "    # Create the geodataframe containing all mean values and geometry for each parameter\n",
    "    xDR_geodf = gpd.GeoDataFrame(df, crs = dst_crs, geometry=gser)\n",
    "    return(xDR_geodf, xDR_df, coord, trans_coord, segy_coord)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions related to parallelization and chunk creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_df(files, JOBS,FM_df, FM_gdf, GeomDF, def_crs):\n",
    "    from joblib import Parallel, delayed\n",
    "    results = Parallel (n_jobs=JOBS)(delayed(RAW2GeoDF)(FM_df, FM_gdf, files[i], GeomDF, def_crs)\n",
    "                            for i in range(len(files)))\n",
    "    return (results)\n",
    "\n",
    "def chunk_creator(item_list, chunksize):\n",
    "    it = iter(item_list)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, chunksize))\n",
    "        if not chunk:\n",
    "            break\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function\n",
    "The main function do:\n",
    "- create a list of all files to be processed\n",
    "- evaluate available RAM and CPU and scale CPU cores\n",
    "- create chunks for smoother parallel processing\n",
    "- load sub-modules for xDR/RAW\n",
    "- initialize all dataframes\n",
    "- drop from geodataframe all the parameter with incompatible 3-dimensional parameters (e.g. MONOPOLE_UNIT_VECTOR)\n",
    "- save complete geopackage or shapefile\n",
    "- filter data of poles and save corresponding geopackage or shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():        \n",
    "    # List all files\n",
    "    file_list = get_paths(DATA_PATH, 'dat')\n",
    "    \n",
    "    # Check available resources\n",
    "    \n",
    "    total_size, max_size, av_fsize = folder_file_size(DATA_PATH,file_list)\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    import psutil\n",
    "    \n",
    "    avram=psutil.virtual_memory().total >> 30\n",
    "    avcores=psutil.cpu_count(logical=False)\n",
    "    avthreads=psutil.cpu_count(logical=True)\n",
    "    ram_thread = avram/avthreads\n",
    "    req_mem = avthreads*max_size\n",
    "    if req_mem > avcores and req_mem > avram:\n",
    "        JOBS = avcores\n",
    "    else:\n",
    "        JOBS = avthreads\n",
    "    \n",
    "    \n",
    "    # Create chunks for parallel processing\n",
    "    filerange = len(file_list)\n",
    "    chunksize = round(filerange/JOBS)\n",
    "    if chunksize <1:\n",
    "        chunksize=1\n",
    "        JOBS = filerange\n",
    "    chunks = []\n",
    "    for c in chunk_creator(file_list, JOBS):\n",
    "        chunks.append(c)\n",
    "               \n",
    "    # Load sub-functions\n",
    "    if DRTYPE in ['RDR', 'rdr','EDR','edr']:\n",
    "        \n",
    "        def_crs = Available_CRS['Planetocentric']\n",
    "        ParamDF=xDR_params()\n",
    "    \n",
    "    elif DRTYPE in ['RAW','raw']:\n",
    "        \n",
    "        def_crs = Available_CRS['Planetocentric']\n",
    "        ParamDF = RAW_params()\n",
    "        \n",
    "    elif DRTYPE in ['FM','fm']:\n",
    "        \n",
    "        def_crs = Available_CRS['Planetocentric']\n",
    "        ParamDF = FM_params()\n",
    "    # Initialize dataframes\n",
    "    xDR_df = xDR_DF(ParamDF)\n",
    "    xDR_gdf = gpd.GeoDataFrame(xDR_df)\n",
    "    results = []\n",
    "    \n",
    "    # Parallel processing\n",
    "    with tqdm(total=len(file_list),\n",
    "             desc = 'Generating files',\n",
    "             unit='File') as pbar:\n",
    "        \n",
    "        for i in range(len(chunks)):\n",
    "            files = chunks[i]    \n",
    "            # print(files)\n",
    "            chunk_results = parallel_df(files, JOBS,xDR_df, xDR_gdf, ParamDF, def_crs)\n",
    "            \n",
    "            for r in chunk_results:\n",
    "                results.append(r)\n",
    "                xDR_df = pd.concat([xDR_df, r[1]])\n",
    "                xDR_gdf = pd.concat([xDR_gdf, r[0]])\n",
    "            pbar.update(JOBS)\n",
    "\n",
    "    # Sort dataframe elements by orbit number and drop incompatible Parameters from dataframe\n",
    "    xDR_df = xDR_df.sort_values(by='name', ascending=True, ignore_index=True)    \n",
    "    xDR_gdf = xDR_gdf.sort_values(by='name', ascending=True, ignore_index=True)    \n",
    "    xDR_gdf = DF_drop(xDR_gdf, DRTYPE)\n",
    "   \n",
    "    if DRVR is None:\n",
    "        print('All Done')\n",
    "        xDR_gdf_NPole = None\n",
    "        xDR_gdf_SPole = None\n",
    "    else:        \n",
    "        # Save geopackages     \n",
    "        print('\\nSaving Full geopackate')    \n",
    "        # geoDF2file(xDR_gdf, 'Complete', marsEQUI180, SAVE_DIR, DRVR)\n",
    "        geoDF2file(xDR_gdf, 'Complete', [DST_CRS, DST_CRS], SAVE_DIR, DRVR)\n",
    "        print('\\nSaving N-Pole geopackage')\n",
    "        xDR_gdf_NPole = gdf_split(xDR_gdf, 65)\n",
    "        geoDF2file(xDR_gdf_NPole, 'NPole', [DST_CRS, Available_CRS['N_pole']], SAVE_DIR, DRVR)\n",
    "        print('\\nSaving S-Pole geopackage')\n",
    "        xDR_gdf_SPole = gdf_split(xDR_gdf, -65)\n",
    "        geoDF2file(xDR_gdf_SPole, 'SPole', [DST_CRS, Available_CRS['S_pole']], SAVE_DIR, DRVR)\n",
    "        print('All done')\n",
    "        \n",
    "        \n",
    "    if DBUP in ['Y','y']:\n",
    "        error = databaseUpdate(xDR_gdf)\n",
    "        if error == False:\n",
    "            print('Database updated')\n",
    "        else:\n",
    "            print(error)\n",
    "        \n",
    "    return(xDR_gdf, xDR_df, xDR_gdf_NPole, xDR_gdf_SPole)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User interactive inputs\n",
    "Ask user for various input:\n",
    "- General output directory\n",
    "- Data directory\n",
    "- Type of file to be saved\n",
    "- Type of file ingested\n",
    "- Save geopackage/shapefile\n",
    "- Save images of both frequencies\n",
    "- Save dumps of both frequencies\n",
    "- Save Seg-y file for both frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    WORK_PATH = input(str('Path of the output folder '))\n",
    "                \n",
    "    DATA_PATH = input(str('Path to data files folder:'))\n",
    "        \n",
    "    DRTYPE = question('Enter data type: EDR/RDR/RAW',['EDR','edr','RDR','rdr','RAW','raw'])\n",
    "    \n",
    "    qst = question('Save geopackagse/shapefiles',  ['Y','y','N','n'])\n",
    "    if qst in ['Y','y']:\n",
    "        DRVR= question('Enter output file type: GPKG/gpkg or SHP/shp', ['GPKG','gpkg','SHP','shp'])\n",
    "    else:\n",
    "        DRVR = None\n",
    "    SAVEIMG = question('Save images?', ['Y','y','N','n'])\n",
    "    \n",
    "    SAVEDUMP = question('Dump arrays?', ['Y','y','N','n'])\n",
    "\n",
    "    SAVESEGY = question('Save Seg-y', ['Y','y','N','n'])\n",
    "    \n",
    "    \n",
    "    if SAVEIMG in ['Y', 'y']:\n",
    "        IMG_DIR = make_folder(WORK_PATH,'Images')\n",
    "    else:\n",
    "        IMG_DIR=None\n",
    "    if SAVEDUMP in ['Y', 'y']:\n",
    "        DUMP_DIR = make_folder(WORK_PATH, 'Dumps')\n",
    "    else:\n",
    "        DUMP_DIR=None\n",
    "    if SAVESEGY in ['Y', 'y']:\n",
    "        SEGY_DIR = make_folder(WORK_PATH, 'Seg-y')\n",
    "    else:\n",
    "        SEGY_DIR = None\n",
    "        \n",
    "    if DRVR in ['GPKG','gpkg']:\n",
    "        SAVE_DIR = make_folder(WORK_PATH,'Geopackages')\n",
    "    elif DRVR in ['SHP', 'shp']:\n",
    "        SAVE_DIR = make_folder(WORK_PATH,'Shapefiles')\n",
    "    else:\n",
    "        DRVR = None\n",
    "   # DST_CRS = input('Destination CRS in wkt/proj4 format - Leave empty for Mars Ecquirectangular') or marsEQUI180\n",
    "    DCRS = question(\"Select destination CRS, leave empty for Planetocentric\", ['Equi','Plane',''])\n",
    "    if DCRS == '' or DCRS =='Plane':\n",
    "        print('plane')\n",
    "        DST_CRS = Available_CRS['Planetocentric']\n",
    "    else:\n",
    "        DST_CRS = Available_CRS['EquidistantCylindrical-180']\n",
    "        \n",
    "    \n",
    "    DBUP = question('Save results into postgres database?',['Y','y','N','n'])\n",
    "\n",
    "    \n",
    "    xDR_gdf = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
